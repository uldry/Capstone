{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Economical news\n",
    "\n",
    "This code scrapes `Forexfactory.com` economical news calendar between a given date and today.\n",
    "\n",
    "The resulting dataframe is then saved in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "import logging\n",
    "import csv\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeeklyNews(Sdate):\n",
    "    '''\n",
    "    This function will fetch the economical news and return them in the form of a dataframe\n",
    "    Any date can be given, but it will get the news for the current week starting on Monday\n",
    "    \n",
    "    Code modified from https://gist.github.com/pohzipohzi/ad7942fc5545675022c1f31123e64c0c#file-forexfactory_econcal-py\n",
    "     (Recursivity was removed, returning dataframe, dealing with URL directly instead of following a link)\n",
    "     \n",
    "    '''\n",
    "    news = pd.DataFrame(columns = ['Datetime','Currency','Event','Actual','Forecast','Previous'])\n",
    "    baseURL = \"https://www.forexfactory.com/calendar.php?week=\"\n",
    "    \n",
    "    PreviousMonday = Sdate.date() - timedelta(days= Sdate.weekday())\n",
    "    URLDatePart = calendar.month_abbr[PreviousMonday.month].lower() + str(PreviousMonday.day) + '.' + str(PreviousMonday.year)\n",
    "    \n",
    "    r = requests.get(baseURL + URLDatePart)\n",
    "    \n",
    "    if  r.status_code == 200: \n",
    "                \n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "        \n",
    "        # get and parse table data, ignoring details and graph\n",
    "        table = soup.find(\"table\", class_=\"calendar__table\")\n",
    "\n",
    "        # do not use the \".calendar__row--grey\" css selector (reserved for historical data)\n",
    "        trs = table.select(\"tr.calendar__row.calendar_row\")\n",
    "        fields = [\"date\",\"time\",\"currency\",\"impact\",\"event\",\"actual\",\"forecast\",\"previous\"]\n",
    "        \n",
    "        curr_year = str(PreviousMonday.year)\n",
    "        curr_date = \"\"\n",
    "        curr_time = \"\"\n",
    "        for tr in trs:\n",
    "\n",
    "            # fields may mess up sometimes, see Tue Sep 25 2:45AM French Consumer Spending\n",
    "            # in that case we append to errors.csv the date time where the error is\n",
    "            try:\n",
    "                for field in fields:\n",
    "                    data = tr.select(\"td.calendar__cell.calendar__{}.{}\".format(field,field))[0]\n",
    "                \n",
    "                    if field==\"date\" and data.text.strip()!=\"\":\n",
    "                        curr_date = data.text.strip()\n",
    "                    elif field==\"time\" and data.text.strip()!=\"\":\n",
    "                        # time is sometimes \"All Day\" or \"Day X\" (eg. WEF Annual Meetings)\n",
    "                        if data.text.strip().find(\"Day\")!=-1:\n",
    "                            curr_time = \"12:00am\"\n",
    "                        else:\n",
    "                            curr_time = data.text.strip()\n",
    "                    elif field==\"currency\":\n",
    "                        currency = data.text.strip()\n",
    "                    elif field==\"impact\":\n",
    "                        # when impact says \"Non-Economic\" on mouseover, the relevant\n",
    "                        # class name is \"Holiday\", thus we do not use the classname\n",
    "                        impact = data.find(\"span\")[\"title\"]\n",
    "                    elif field==\"event\":\n",
    "                        event = data.text.strip()\n",
    "                    elif field==\"actual\":\n",
    "                        actual = data.text.strip()\n",
    "                    elif field==\"forecast\":\n",
    "                        forecast = data.text.strip()\n",
    "                    elif field==\"previous\":\n",
    "                        previous = data.text.strip()\n",
    "\n",
    "                \n",
    "                news = news.append({'Datetime':str(datetime.strptime(\",\".join([curr_year,curr_date,curr_time]),\"%Y,%a%b %d,%I:%M%p\")), 'Currency':currency, 'Impact':impact,'Event':event, 'Actual':actual,'Forecast':forecast,'Previous':previous}, ignore_index=True)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "                # It seems that errors are caused by duplicates that have some fields missing\n",
    "\n",
    "    else: print(\"There was an error \",r.status_code,\" while retrieving the following URL: \",baseURL + URLDatePart)\n",
    "    \n",
    "    return(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllNews(startDate,endDate):\n",
    "    '''\n",
    "    Get all weekly news between two dates\n",
    "    Returns a dataframe of all the news between the weeks that the given dates belongs to.\n",
    "    '''\n",
    "    Ndf = pd.DataFrame(columns = ['Datetime','Currency','Event','Actual','Forecast','Previous'])\n",
    "    \n",
    "    # Calculate the number of weeks to retrieve, more is okay.\n",
    "    NWeeks = math.ceil((endDate- startDate).days / 7)\n",
    "    for week in range(0,NWeeks,1):\n",
    "        print(\"X\", end=\"\", flush=True)\n",
    "        Ndf= Ndf.append(getWeeklyNews(startDate + timedelta(days=(week*7))), ignore_index=True)\n",
    "    print(\"\\n\", Ndf.shape[0], \"news are in the dataframe\")\n",
    "    return((Ndf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now()\n",
    "start_date = datetime(2019,11,1,12,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXXXXXXXX\n",
      " 1999 news are in the dataframe\n"
     ]
    }
   ],
   "source": [
    "N = getAllNews(start_date, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.to_csv(\"./EconomicalNews.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
